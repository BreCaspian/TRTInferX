## Download

Prebuilt models and inference artifacts are available at:

ğŸ”— https://github.com/BreCaspian/TRTInferX/releases

---

## Model Files Structure

After downloading and extracting, the model directory structure is as follows:

```text
models/
â”œâ”€â”€ exports/
â”‚   â”œâ”€â”€ best_fp16_b1.engine
â”‚   â”œâ”€â”€ best_fp16_b4.engine
â”‚   â”œâ”€â”€ best_fp16_b8.engine
â”‚   â”œâ”€â”€ best_fp16_b16.engine
â”‚   â”œâ”€â”€ best_fp16_b32.engine
â”‚   â”œâ”€â”€ best_fp16_b64.engine
â”‚   â”œâ”€â”€ best_fp16_b128.engine
â”‚   â”œâ”€â”€ best_fp16_b1_16_dynamic.engine
â”‚   â”œâ”€â”€ best_int8_b1.engine
â”‚   â”œâ”€â”€ best_int8_b4.engine
â”‚   â”œâ”€â”€ best_int8_b8.engine
â”‚   â”œâ”€â”€ best_int8_b16.engine
â”‚   â”œâ”€â”€ best_int8_b32.engine
â”‚   â”œâ”€â”€ best_int8_b64.engine
â”‚   â”œâ”€â”€ best_int8_b128.engine
â”‚   â”œâ”€â”€ best_int8_b1_16_dynamic.engine
â”‚   â”œâ”€â”€ best.onnx
â”‚   â”œâ”€â”€ best_raw.onnx
â”‚   â””â”€â”€ calib.bin
â””â”€â”€ initial/
    â”œâ”€â”€ yolo11n.onnx
    â””â”€â”€ yolo11n.pt
```


------

## Notes

- `exports/` contains exported ONNX models and TensorRT engines for different
  precisions (`FP16`, `INT8`) and batch sizes.
- Dynamic batch engines support batch sizes in the range `1â€“16`.
- `calib.bin` is required for INT8 inference.
- `initial/` contains the original training checkpoints and ONNX model.

For model export or regeneration, please refer to the instructions in the README.

---

<p align="center">
  <img src="../../docs/Horizon.png" width="200" alt="Horizon Team">
</p>

<div align="center">

Copyright Â© 2026 ROBOMASTER Â· ååŒ—ç†å·¥å¤§å­¦ HORIZON æˆ˜é˜Ÿ Â· é›·è¾¾ç»„ - YAOYUZHUO<br/>
Licensed under the GNU Affero General Public License v3.0 (AGPL-3.0).<br/>
Use, modification, and redistribution are permitted under the terms of AGPL-3.0.<br/>
The complete corresponding source must be made available.<br/>
2026 å¹´ 01 æœˆ 08 æ—¥

</div>